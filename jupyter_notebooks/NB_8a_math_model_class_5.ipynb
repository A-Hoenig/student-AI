{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **STUDENT AI** - MATH MODEL CREATION (CLASSIFICATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "Create a classification model to predict Math score based on Key dataset features. Numerical variables will be grouped into bins. <br> \n",
        "Initially I will try to use 5, analog to the EDA study grouping student performance based on the mean value and 1-2 standard deviations from mean. That would allow the model to predict students in the fail, below average, average, above average and exeptional categories. - however accuracy is still a concearn, so alternative classification will be analysed using 3 bins. This will allow prediction of below average, average and above average performance and will probably achieve higher accuracy in prediction. <br>\n",
        "Worst case, the dataset would have to be grouped into 2 bins around the mean allowing classification into below average and above average.\n",
        "\n",
        "This would flag many more students however of needing additional assistance. \n",
        "\n",
        "## Inputs\n",
        "\n",
        "Continues to assess dataset loaded in previous notebook.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "None. Assess whether the optimum 5 bin classification approach is viable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build Pipeline for classification model to predict Math numerical target variable\n",
        "\n",
        "The steps for a classification model are a little more involved when using a dataset with a numerical target variable\n",
        "\n",
        "| Step |  Purpose | \n",
        "|---|---|\n",
        "|Data Cleaning|Deal with missing data or wrong data - step already completed in the saved dataset|\n",
        "|Discretize Numerical Target|group target variable into bins for categorization|\n",
        "|Encode Categorical Features|Model algorithms can only handle numerical data. Needs to be converted first|\n",
        "|Data Balancing|Classification models are affected negatively by imbalanced data. SMOTE or Undersampling needs to be performed to balance the dataset|\n",
        "|Feature Smart Correlation|Determine which features are most significant and eliminate uneccessary ones - helps prevent overfitting - **not neccesary**|\n",
        "|Feature Selection|Select which features will be used |\n",
        "|Algorithm Selection|Assess best algorithm for the data set as well as the best associated Parameters and Hyperparameters|\n",
        "|Model Training|Train the model on the train data and evaluate with the test set|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All Libraries Loaded\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspace/.pyenv_mirror/user/3.8.18/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  from pandas import MultiIndex, Int64Index\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "### Pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "### Feature Engineering\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "\n",
        "### Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "### libraries for custom transformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "### Feature Balancing\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "### Feature  Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "### ML algorithms \n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier \n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "### EqualFrequencyDiscretiser\n",
        "from feature_engine.discretisation import EqualFrequencyDiscretiser\n",
        "\n",
        "### packages for classification report and confusion matrix\n",
        "from sklearn.metrics import make_scorer, recall_score\n",
        "\n",
        "### Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "### Packages for generating a classification report and confusion matrix\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "### GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "print('All Libraries Loaded')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "### Set the working directory to notebook parent folder\n",
        "If the output does not match, click **'clear all outputs'** and then **'restart'** the notebook. \n",
        "Then run cells from top to bottom."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "If correct, Active Directory should read: /workspace/student-AI\n",
            "Active Directory: /workspace/student-AI\n"
          ]
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "os.chdir(os.path.dirname(current_dir))\n",
        "current_dir = os.getcwd()\n",
        "print('If correct, Active Directory should read: /workspace/student-AI')\n",
        "print(f\"Active Directory: {current_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load cleaned dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>EthnicGroup</th>\n",
              "      <th>ParentEduc</th>\n",
              "      <th>LunchType</th>\n",
              "      <th>TestPrep</th>\n",
              "      <th>ParentMaritalStatus</th>\n",
              "      <th>PracticeSport</th>\n",
              "      <th>IsFirstChild</th>\n",
              "      <th>NrSiblings</th>\n",
              "      <th>TransportMeans</th>\n",
              "      <th>WklyStudyHours</th>\n",
              "      <th>MathScore</th>\n",
              "      <th>ReadingScore</th>\n",
              "      <th>WritingScore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>female</td>\n",
              "      <td>C</td>\n",
              "      <td>bachelor</td>\n",
              "      <td>standard</td>\n",
              "      <td>not completed</td>\n",
              "      <td>married</td>\n",
              "      <td>regularly</td>\n",
              "      <td>yes</td>\n",
              "      <td>3</td>\n",
              "      <td>schoolbus</td>\n",
              "      <td>Less than 5 hours</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>C</td>\n",
              "      <td>college</td>\n",
              "      <td>standard</td>\n",
              "      <td>not completed</td>\n",
              "      <td>married</td>\n",
              "      <td>sometimes</td>\n",
              "      <td>yes</td>\n",
              "      <td>0</td>\n",
              "      <td>schoolbus</td>\n",
              "      <td>Between 5-10 hours</td>\n",
              "      <td>69</td>\n",
              "      <td>90</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>female</td>\n",
              "      <td>B</td>\n",
              "      <td>masters</td>\n",
              "      <td>standard</td>\n",
              "      <td>not completed</td>\n",
              "      <td>single</td>\n",
              "      <td>sometimes</td>\n",
              "      <td>yes</td>\n",
              "      <td>4</td>\n",
              "      <td>schoolbus</td>\n",
              "      <td>Less than 5 hours</td>\n",
              "      <td>87</td>\n",
              "      <td>93</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>A</td>\n",
              "      <td>associates</td>\n",
              "      <td>free</td>\n",
              "      <td>not completed</td>\n",
              "      <td>married</td>\n",
              "      <td>never</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>schoolbus</td>\n",
              "      <td>Between 5-10 hours</td>\n",
              "      <td>45</td>\n",
              "      <td>56</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>male</td>\n",
              "      <td>C</td>\n",
              "      <td>college</td>\n",
              "      <td>standard</td>\n",
              "      <td>not completed</td>\n",
              "      <td>married</td>\n",
              "      <td>sometimes</td>\n",
              "      <td>yes</td>\n",
              "      <td>0</td>\n",
              "      <td>schoolbus</td>\n",
              "      <td>Between 5-10 hours</td>\n",
              "      <td>76</td>\n",
              "      <td>78</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Gender EthnicGroup  ParentEduc LunchType       TestPrep  \\\n",
              "0  female           C    bachelor  standard  not completed   \n",
              "1  female           C     college  standard  not completed   \n",
              "2  female           B     masters  standard  not completed   \n",
              "3    male           A  associates      free  not completed   \n",
              "4    male           C     college  standard  not completed   \n",
              "\n",
              "  ParentMaritalStatus PracticeSport IsFirstChild  NrSiblings TransportMeans  \\\n",
              "0             married     regularly          yes           3      schoolbus   \n",
              "1             married     sometimes          yes           0      schoolbus   \n",
              "2              single     sometimes          yes           4      schoolbus   \n",
              "3             married         never           no           1      schoolbus   \n",
              "4             married     sometimes          yes           0      schoolbus   \n",
              "\n",
              "       WklyStudyHours  MathScore  ReadingScore  WritingScore  \n",
              "0   Less than 5 hours         71            71            74  \n",
              "1  Between 5-10 hours         69            90            88  \n",
              "2   Less than 5 hours         87            93            91  \n",
              "3  Between 5-10 hours         45            56            42  \n",
              "4  Between 5-10 hours         76            78            75  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(f\"outputs/dataset/Expanded_data_with_more_features_clean.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "nrSiblings is treated as a numerical variable. As I determined previously it has no bearing on the target variables, so I will drop it rather than convert to categorical. The other variables previously identified in the EDA as having not much impact, I will keep in, as the Feature Selection step did not suggest to eliminate any. I will also drop teh features that the EDA determined has no bearing on the target variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>EthnicGroup</th>\n",
              "      <th>ParentEduc</th>\n",
              "      <th>LunchType</th>\n",
              "      <th>TestPrep</th>\n",
              "      <th>MathScore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>female</td>\n",
              "      <td>C</td>\n",
              "      <td>bachelor</td>\n",
              "      <td>standard</td>\n",
              "      <td>not completed</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>female</td>\n",
              "      <td>C</td>\n",
              "      <td>college</td>\n",
              "      <td>standard</td>\n",
              "      <td>not completed</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>female</td>\n",
              "      <td>B</td>\n",
              "      <td>masters</td>\n",
              "      <td>standard</td>\n",
              "      <td>not completed</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>A</td>\n",
              "      <td>associates</td>\n",
              "      <td>free</td>\n",
              "      <td>not completed</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>male</td>\n",
              "      <td>C</td>\n",
              "      <td>college</td>\n",
              "      <td>standard</td>\n",
              "      <td>not completed</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Gender EthnicGroup  ParentEduc LunchType       TestPrep  MathScore\n",
              "0  female           C    bachelor  standard  not completed         71\n",
              "1  female           C     college  standard  not completed         69\n",
              "2  female           B     masters  standard  not completed         87\n",
              "3    male           A  associates      free  not completed         45\n",
              "4    male           C     college  standard  not completed         76"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_math = df.drop(['ReadingScore', 'WritingScore','NrSiblings','ParentMaritalStatus', 'PracticeSport','IsFirstChild','NrSiblings','WklyStudyHours','TransportMeans'], axis=1)\n",
        "df_math.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PipelineOptimization(model):\n",
        "    pipeline_base = ImbPipeline([\n",
        "\n",
        "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(\n",
        "            encoding_method='arbitrary', \n",
        "            variables=[\n",
        "                'Gender',\n",
        "                'EthnicGroup',\n",
        "                'ParentEduc',\n",
        "                'LunchType',\n",
        "                'TestPrep',\n",
        "                ])),\n",
        "\n",
        "        #(\"undersample\", RandomUnderSampler()),  # Assuming enough data values - another option will be SMOTE\n",
        "        # (\"oversample\", SMOTE()),  # alternate balancing technique -- only allow one or teh other until best option is determined\n",
        "\n",
        "        (\"feature_selection\", SelectFromModel(model)),\n",
        "\n",
        "        (\"model\", model),\n",
        "\n",
        "    ])\n",
        "\n",
        "    return pipeline_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_algorithm_list = {\n",
        "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
        "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
        "}\n",
        "\n",
        "parameters_list = {\n",
        "    \"XGBClassifier\":{},\n",
        "    \"DecisionTreeClassifier\":{},\n",
        "    \"RandomForestClassifier\":{},\n",
        "    \"GradientBoostingClassifier\":{},\n",
        "    \"ExtraTreesClassifier\":{},\n",
        "    \"AdaBoostClassifier\":{},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Confusion Matrix Function from CI Customer Churn Course"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def confusion_matrix_and_report(x, y, pipeline, label_map):\n",
        "\n",
        "  prediction = pipeline.predict(x)\n",
        "\n",
        "  print('---  Confusion Matrix  ---')\n",
        "  print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
        "        columns=[ [\"Actual \" + sub for sub in label_map] ], \n",
        "        index= [ [\"Prediction \" + sub for sub in label_map ]]\n",
        "        ))\n",
        "  print(\"\\n\")\n",
        "\n",
        "  print('---  Classification Report  ---')\n",
        "  print(classification_report(y, prediction, target_names=label_map),\"\\n\")\n",
        "\n",
        "def clf_performance(math_train_features, math_train_scores, math_test_features, math_test_scores, pipeline, label_map):\n",
        "  print(\"#### Train Set #### \\n\")\n",
        "  confusion_matrix_and_report(math_train_features, math_train_scores, pipeline, label_map)\n",
        "\n",
        "  print(\"#### Test Set ####\\n\")\n",
        "  confusion_matrix_and_report(math_test_features, math_test_scores, pipeline, label_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Hyperparameter search class (same as previous notebook)\n",
        "\n",
        "To select the best algorithm and hyperparameters we will fit a model with each different type / parameter set and compare the results.\n",
        "To do this I can use the custom parameter test function, derived in the CodeInstitute Churnometer Walkthrough [here](https://github.com/AdamBoley/churnometer/blob/main/jupyter_notebooks/06%20-%20Modeling%20and%20Evaluation%20-%20Predict%20Tenure.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, parameters):\n",
        "        self.models = models\n",
        "        self.parameters = parameters\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, x, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "            model =  PipelineOptimization(self.models[key])\n",
        "\n",
        "            parameters = self.parameters[key]\n",
        "            grid_search = GridSearchCV(model, parameters, cv=cv, n_jobs=n_jobs, verbose=verbose, scoring=scoring)\n",
        "            grid_search.fit(x, y)\n",
        "            self.grid_searches[key] = grid_search\n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, parameters):\n",
        "            summary = {\n",
        "                 'estimator': key,\n",
        "                 'minimum_score': min(scores),\n",
        "                 'maximum_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'standard_deviation_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**parameters,**summary})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            parameters = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                result = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(result.reshape(len(parameters), 1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(parameters, all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'minimum_score', 'mean_score', 'maximum_score', 'standard_deviation_score']\n",
        "        columns = columns + [column for column in df.columns if column not in columns]\n",
        "\n",
        "        return df[columns], self.grid_searches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create custom transformer to discretize the dataframe based on 5, 3 or 2 bins.\n",
        "Criteria for boundaries is based on calculated mean and standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomDiscretizer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Custom Transformer to automatically generate categorical bins from a numerical variable\n",
        "    Arguments are a pandas dataframe, the number of bins and the column(s) to discretize\n",
        "    bins are sized based on the column mean value and standard deviation\n",
        "    2 bins are spit at the mean\n",
        "    3 bins are split +- 1/2 the SD\n",
        "    5 bins are split at the  mean with 1*SD and 2*Sd as the cutoff\n",
        "    If wrong bin argument is given, defaults to 5\n",
        "    No column arg = use all columns (default)\n",
        "    \"\"\"\n",
        "    def __init__(self, n_bins=3, columns=None):\n",
        "        if n_bins not in [2, 3, 5]:\n",
        "            print(\"Error: n_bins must be : [2, 3 or 5]. Setting 5 as default.\")\n",
        "            self.n_bins = 5  # Default\n",
        "        else:\n",
        "            self.n_bins = n_bins\n",
        "        self.columns = columns\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        # not needed\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        # Ensure X is a DataFrame\n",
        "        X_transformed = X.copy()\n",
        "        # If columns param is None, apply to all columns\n",
        "        columns_to_discretize = self.columns if self.columns is not None else X.columns\n",
        "        \n",
        "        for column in columns_to_discretize:\n",
        "            if column in X.columns:  # Check column exists\n",
        "                mean = X[column].mean()\n",
        "                std = X[column].std()\n",
        "                min_val = X[column].min()\n",
        "                max_val = X[column].max()\n",
        "\n",
        "                if self.n_bins == 5:\n",
        "                    bins = [min_val-1, mean - 2*std, mean - std, mean, mean + std, max_val+1]\n",
        "                    labels = [0, 1, 2, 3, 4]\n",
        "                \n",
        "                elif self.n_bins == 3:\n",
        "                    bins = [min_val-1, mean - std/2, mean + std/2, max_val+1]\n",
        "                    labels = [0, 1, 2]\n",
        "                \n",
        "                elif self.n_bins == 2:\n",
        "                    bins = [min_val-1, mean, max_val+1]\n",
        "                    labels = [0, 1]\n",
        "\n",
        "                X_transformed[column] = pd.cut(X[column], bins=bins, labels=labels, include_lowest=True)\n",
        "            else:\n",
        "                # If the column is not in the DataFrame,  raise an error or warn\n",
        "                print(f\"Column {column} not found in DataFrame!\")\n",
        "        \n",
        "        return X_transformed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test CustomDiscretizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "discretizer = CustomDiscretizer(n_bins=5, columns=['MathScore'])\n",
        "df_transformed = discretizer.fit_transform(df_math)\n",
        "df_transformed.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize custom created bins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 3))\n",
        "\n",
        "# Original distribution\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(df['MathScore'], bins='auto', kde=True)\n",
        "plt.title('Original Distribution')\n",
        "\n",
        "# Discretized distribution\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(df_transformed['MathScore'], bins='auto', kde=False)\n",
        "plt.title('Discretized Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Start model tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "math_train_features, math_test_features, math_train_scores, math_test_scores = train_test_split(\n",
        "    df_transformed.drop(['MathScore'], axis=1),\n",
        "    df_transformed['MathScore'],\n",
        "    test_size = 0.2,\n",
        "    random_state = 7\n",
        ")\n",
        "\n",
        "print(\"* Train set:\", math_train_features.shape, math_train_scores.shape, \"\\n* Test set:\",  math_test_features.shape, math_test_scores.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check distribution of training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "math_train_scores.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Balance Data\n",
        "This plot shows the data is very imbalanced, especially teh fail grades (0). Since I am primarily interested in lower performing students and there are many datarows and the majority is in the average category (3) I will use undersample to randomly remove values from the majority values. This will likely greatly reduce teh total rows, but should still be enough to train the model on and then test on the reserved test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "undersample = RandomUnderSampler(random_state=0)\n",
        "math_train_features, math_train_scores = undersample.fit_resample(math_train_features, math_train_scores)\n",
        "print(math_train_features.shape, math_train_scores.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check balanced plot..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "math_train_scores.value_counts().plot(kind='bar', title='Train Set Target Distribution (Balanced)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis\n",
        "This plot shows the resulting Target distribution is now well balanced and as predicted greatly reduced in numbers (2865 rows vs 30000+)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_search = HyperparameterOptimizationSearch(models=models_algorithm_list, parameters=parameters_list)\n",
        "model_search.fit(math_train_features, math_train_scores, scoring=make_scorer(recall_score, labels=[0], average=None), n_jobs=-1, cv=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_grid_search_summary, model_grid_search_pipelines = model_search.score_summary(sort_by='mean_score')\n",
        "model_grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis\n",
        "The algorithm search shows the best Classifier is the XGBClassifier with a mean score of 0.7715. This is above the desired value of 0.6 si I will proceed with it. GradientBoost is significantly lower at 0.577, so I dont expect it to improve to a better position, even with some optimized hyperparameters. The next step will therfore use the 2 best Classifiers and generate results for different hyperparameter combinations to see if the value can be improved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define Hyperparameter list for 2 best models and apply to evaluate the best options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_models = {\n",
        "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
        "    # \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
        "}\n",
        " \n",
        "test_parameters = {\n",
        "    \"XGBClassifier\":{'model__n_estimators': [30,80,200],\n",
        "                      'model__max_depth': [None, 3, 15],\n",
        "                      'model__learning_rate': [0.01,0.1,0.001],\n",
        "                      'model__gamma': [0, 0.1],\n",
        "                            },\n",
        "\n",
        "    \"GradientBoostingClassifier\":{'model__n_estimators': [100,50,140],\n",
        "                                  'model__learning_rate':[0.1, 0.01, 0.001],\n",
        "                                  'model__max_depth': [3,15, None],\n",
        "                                  'model__min_samples_split': [2,50],\n",
        "                                  'model__min_samples_leaf': [1,50],\n",
        "                                  'model__max_leaf_nodes': [None,50],\n",
        "                            },\n",
        "\n",
        "    # \"AdaBoostClassifier\":{'model__n_estimators': [50,25,80,150],\n",
        "    #                       'model__learning_rate':[1,0.1, 2],\n",
        "    #                         }\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parameters_search = HyperparameterOptimizationSearch(models=best_models, parameters=test_parameters)\n",
        "parameters_search.fit(math_train_features, math_train_scores, scoring=make_scorer(recall_score, labels=[0], average=None), n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "parameters_grid_search_summary, parameters_grid_search_pipelines = parameters_search.score_summary(sort_by='mean_score')\n",
        "parameters_grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis\n",
        "Unfortunately trying different hyperparameters had no effect, so teh default values will be passed to the final pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "maths_best_model = parameters_grid_search_summary.iloc[0,0]\n",
        "maths_best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "maths_best_parameters = parameters_grid_search_pipelines[maths_best_model].best_params_\n",
        "maths_best_parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline_classifier = parameters_grid_search_pipelines[maths_best_model].best_estimator_\n",
        "pipeline_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_cleaning_feat_eng_steps = 1\n",
        "columns_after_data_cleaning_feat_eng = (Pipeline(pipeline_classifier.steps[:data_cleaning_feat_eng_steps])\n",
        "                                        .transform(math_train_features)\n",
        "                                        .columns)\n",
        "\n",
        "best_features = columns_after_data_cleaning_feat_eng[pipeline_classifier['feature_selection'].get_support()].to_list()\n",
        "\n",
        "# create DataFrame to display feature importance\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "          'Feature': columns_after_data_cleaning_feat_eng[pipeline_classifier['feature_selection'].get_support()],\n",
        "          'Importance': pipeline_classifier['model'].feature_importances_})\n",
        "  .sort_values(by='Importance', ascending=False)\n",
        "  )\n",
        "\n",
        "maths_best_features = df_feature_importance['Feature'].to_list() # reassign best features in order\n",
        "\n",
        "# Most important features statement and plot\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
        "      f\"The model was trained on them: \\n{best_features}\")\n",
        "\n",
        "df_feature_importance.plot(kind='bar',x='Feature',y='Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis\n",
        "The hyperparameter optimiztion and pipeline test has narrowed down the feature importance to a single one, albeit the one teh EDA also showed to be of significance. However, using it as the sole feature might not be a good way forward. Below I will assess the predictive power against the test set of data split earlier on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_map = ['Fail', 'Below Average','Average','Above Average','Exceptional']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_performance(math_train_features, math_train_scores, math_test_features, math_test_scores, pipeline_classifier, label_map )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "Unfortunately the test shows that the model is not able to predict any classes between the extremes and is so low the function throws an error and outputs 0. The recall of 0.82 and 0.88 for fail and exceptional might seem usable, but the majority of the students will fall within the mean +- 1 SD so this will not be of much use. \n",
        "\n",
        "I will repeat the pipeline optimization using 3 instead of 5 bins to see if that improves the predictive power."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
