{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **STUDENT AI** - DATA CLEANING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "Inspect the dataset and solve any issues that might arise from wrong data types, or missing / wrong values\n",
        "\n",
        "## Inputs\n",
        "\n",
        "Continues to assess dataset loaded in previous notebook.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "Saves the cleaned dataset back to inputs/dataset folder for futher use\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "PydanticImportError",
          "evalue": "`BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.6/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.6/u/import-error",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPydanticImportError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/workspace/student-AI/jupyter_notebooks/NB_2_data_cleaning.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ahoenig-studentai-klv6sc6taj2.ws-eu108.gitpod.io/workspace/student-AI/jupyter_notebooks/NB_2_data_cleaning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ahoenig-studentai-klv6sc6taj2.ws-eu108.gitpod.io/workspace/student-AI/jupyter_notebooks/NB_2_data_cleaning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ahoenig-studentai-klv6sc6taj2.ws-eu108.gitpod.io/workspace/student-AI/jupyter_notebooks/NB_2_data_cleaning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m \u001b[39mimport\u001b[39;00m ProfileReport\n\u001b[1;32m      <a href='vscode-notebook-cell://ahoenig-studentai-klv6sc6taj2.ws-eu108.gitpod.io/workspace/student-AI/jupyter_notebooks/NB_2_data_cleaning.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAll Libraries Loaded\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/3.8.18/lib/python3.8/site-packages/pandas_profiling/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"Main module of pandas-profiling.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m.. include:: ../../README.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mwarnings\u001b[39;00m \u001b[39mimport\u001b[39;00m warn\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompare_reports\u001b[39;00m \u001b[39mimport\u001b[39;00m compare\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontroller\u001b[39;00m \u001b[39mimport\u001b[39;00m pandas_decorator\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprofile_report\u001b[39;00m \u001b[39mimport\u001b[39;00m ProfileReport\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/3.8.18/lib/python3.8/site-packages/pandas_profiling/compare_reports.py:6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, List, Optional, Tuple, Union\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m Correlation, Settings\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malerts\u001b[39;00m \u001b[39mimport\u001b[39;00m Alert\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprofile_report\u001b[39;00m \u001b[39mimport\u001b[39;00m ProfileReport\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/3.8.18/lib/python3.8/site-packages/pandas_profiling/config.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Dict, List, Optional, Tuple, Union\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39myaml\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel, BaseSettings, Field, PrivateAttr\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_merge_dictionaries\u001b[39m(dict1: \u001b[39mdict\u001b[39m, dict2: \u001b[39mdict\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m     11\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m    Recursive merge dictionaries.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m    :return: Merged dictionary\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/3.8.18/lib/python3.8/site-packages/pydantic/__init__.py:374\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m    372\u001b[0m dynamic_attr \u001b[39m=\u001b[39m _dynamic_imports\u001b[39m.\u001b[39mget(attr_name)\n\u001b[1;32m    373\u001b[0m \u001b[39mif\u001b[39;00m dynamic_attr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     \u001b[39mreturn\u001b[39;00m _getattr_migration(attr_name)\n\u001b[1;32m    376\u001b[0m package, module_name \u001b[39m=\u001b[39m dynamic_attr\n\u001b[1;32m    378\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimportlib\u001b[39;00m \u001b[39mimport\u001b[39;00m import_module\n",
            "File \u001b[0;32m/workspace/.pyenv_mirror/user/3.8.18/lib/python3.8/site-packages/pydantic/_migration.py:296\u001b[0m, in \u001b[0;36mgetattr_migration.<locals>.wrapper\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[39mreturn\u001b[39;00m import_string(REDIRECT_TO_V1[import_path])\n\u001b[1;32m    295\u001b[0m \u001b[39mif\u001b[39;00m import_path \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpydantic:BaseSettings\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m     \u001b[39mraise\u001b[39;00m PydanticImportError(\n\u001b[1;32m    297\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m`BaseSettings` has been moved to the `pydantic-settings` package. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    298\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSee https://docs.pydantic.dev/\u001b[39m\u001b[39m{\u001b[39;00mversion_short()\u001b[39m}\u001b[39;00m\u001b[39m/migration/#basesettings-has-moved-to-pydantic-settings \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    299\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfor more details.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    300\u001b[0m     )\n\u001b[1;32m    301\u001b[0m \u001b[39mif\u001b[39;00m import_path \u001b[39min\u001b[39;00m REMOVED_IN_V2:\n\u001b[1;32m    302\u001b[0m     \u001b[39mraise\u001b[39;00m PydanticImportError(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`\u001b[39m\u001b[39m{\u001b[39;00mimport_path\u001b[39m}\u001b[39;00m\u001b[39m` has been removed in V2.\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mPydanticImportError\u001b[0m: `BaseSettings` has been moved to the `pydantic-settings` package. See https://docs.pydantic.dev/2.6/migration/#basesettings-has-moved-to-pydantic-settings for more details.\n\nFor further information visit https://errors.pydantic.dev/2.6/u/import-error"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pandas_profiling import ProfileReport\n",
        "\n",
        "print('All Libraries Loaded')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "### Set the working directory to notebook parent folder\n",
        "If the output does not match, click **'clear all outputs'** and then **'restart'** the notebook. \n",
        "Then run cells from top to bottom."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "os.chdir(os.path.dirname(current_dir))\n",
        "current_dir = os.getcwd()\n",
        "print('If correct, Active Directory should read: /workspace/student-AI')\n",
        "print(f\"Active Directory: {current_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load saved dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(f\"inputs/dataset/Expanded_data_with_more_features.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Drop Unnamed column that pandas created on import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summarize Dataset Again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "At first glance, 30000+ data rows is a very robust dataset to be able to train an ML. <br>\n",
        "There seems to be no reason why the NrSiblings should be a float data type as you cannot have 0.25 of a brother/sister\n",
        "I will convert nrSiblings to a string type as it needs to be treated as a categorcial valriable and not a numerical one. - however this throws an error as the dataset seems to have NaN or Inf data, so first we deal with missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check for missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_values = df.isnull().sum()\n",
        "percentage_missing = (missing_values / len(df)) * 100\n",
        "percentage_missing = percentage_missing.round(1)\n",
        "missing_data = pd.DataFrame({'Missing_Values': missing_values, 'Percentage_Missing': percentage_missing})\n",
        "missing_data['Percentage_Missing'] = missing_data['Percentage_Missing'].astype(str) + '%'\n",
        "missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Assess how many rows would need to be dropped..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dropped_data = df.dropna()\n",
        "dropped_data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initial Assumptions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Dropping null values leaves us with 19243 data rows ... I hypothesize that while this seems like enough data to still achieve the business requirement, dropping this many values will likely induce an imbalance to the data and bias the dataset. If confirmed, then imputing logical values to fill the gaps is more advisable.\n",
        "* The Pandas report shows **Alerts** under the nrSiblings variable as it assumes that a value of zero (0) could be a problem. In this case, it can be ignored, as a value of zero (0) is valid and indicates an only child.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assessing imbalance on 'dropped' dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pandas_report = ProfileReport(df=dropped_data, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pandas Report on 'dropped' dataset\n",
        "\n",
        "Clicking on each variable to view the specific report fo each variable:\n",
        "\n",
        "| Variable |  Obvious Insights  | \n",
        "|---|---|\n",
        "| Gender  |  shows equal disribution of 50.8% to 49.2% and no missing values |\n",
        "|EthnicGroup|report is not much value as it gives the word 'group' most emphasis - **string 'group ' needs to be removed from data**|\n",
        "|ParentEduc|again here the word 'some' is not accurate. this categorical variable should be changed to a linear numerical one indicating 0 none to n highest level of education, with 'some as intermediary values|\n",
        "|LunchType|this feature is imbalanced with 64.8% standard and 35.2% free/reduced. Will require some feature engineering|\n",
        "|TestPrep|this feature is imbalanced with 65.4% completed and 34.6% none. Will require some feature engineering|\n",
        "|ParentMaritalStatus|this feature is imbalanced with the majority rows (57.2%) labelled married|\n",
        "|practiceSport|this feature is imbalanced with the majority rows (50.5%) labelled sometimes will need to be engineered or dropped|\n",
        "|IsFirstChild|this feature is imbalanced with 64.5% yes and 35.6% no. Will require some feature engineering|\n",
        "|NrSiblings|this numerical feature looks skewed and has a few outliers that might be able to be removed - further analysis required|\n",
        "|TransportMeans|this feature is slightly imbalanced 58.6% private vs 41.4% school_bus|\n",
        "|WklyStudyHours|this is a categorical feature with options <5, 5-10 ,and >10 hours ... distribution is reasonable balanced 39.3%/32.4%/28.3%|\n",
        "|MathScore|at first glance looks like normal distribution, but obvious missing values that were dropped|\n",
        "|ReadingScore|at first glance looks like normal distribution, but more obvious missing values that were dropped|\n",
        "|WritingScore|at first glance looks like normal distribution, but some missing values that were dropped|\n",
        "\n",
        "\n",
        "### dropping the missing value data rows has indeed induced an imbalance to the dataset. I will therefore assess the viability of imputing data to fill the gaps..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imputing Missing Values\n",
        "let's review the missing_data form the full dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The highest missing data rate is TransportMeans at 10.2%. Thinking logically about how this feature might affect overall school performance of a student, it seems that this is an indicator of economic status of the family.\n",
        "Another indicator of economic status of the family is LunchType, indicating whether the family has the means available to pay for own school lunches. This feature has no missing values.\n",
        "\n",
        "I will therefore **drop the TransportMeans** feature as it has many missing values and a single indicator of Family economic status should be sufficient in assessing its effect on school performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop(columns=['TransportMeans'], inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imputing Categorical Variables\n",
        "\n",
        "Categorical variables with missing values are :\n",
        "* 'EthnicGroup'\n",
        "* 'TestPrep'\n",
        "* 'ParentEduc'\n",
        "* 'ParentMaritalStatus'\n",
        "* 'IsFirstChild'\n",
        "* 'PracticeSport'\n",
        "* 'WklyStudyHours'\n",
        "* ('LunchType' and 'Gender' have no missing values and do not need to be adjusted)\n",
        "\n",
        "For these categorical variables I will insert the most common value from the dataset (mode) as that will be closest to the actual value probabalistically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for column in ['EthnicGroup', 'TestPrep', 'ParentEduc', 'ParentMaritalStatus', 'IsFirstChild', 'PracticeSport', 'WklyStudyHours']:\n",
        "    mode_value = df[column].mode()[0]\n",
        "    df[column].fillna(mode_value, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imputing Numerical Variables\n",
        "\n",
        "The only numerical variable from the feature set (not counting the scores which have no missing values) is NrSiblings.\n",
        "Once the missing values have been imputed, I can also change the data type to a more sensical integer rather than float.\n",
        "The imputed values will be based on the **median** instead of the **mean** as this is less sensitive to outliers since the variable does contain some 'extreme' values of 6 or more siblings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "median_value = df['NrSiblings'].median()\n",
        "df['NrSiblings'] = df['NrSiblings'].fillna(median_value).astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick check for remaining missing values and check datatype change and possible duplicate values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['NrSiblings'].dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert nrSiblings Variable to categorical by changing dtype to  string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['NrSiblings'] = df['NrSiblings'].astype(str)\n",
        "df['NrSiblings'].dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The data is now clean and logical values have been added, in the next book I will conduct an EDA to go into detail about the feature set and data distribution / balance. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save file to repository for follow on notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = 'outputs/dataset/Expanded_data_with_more_features_clean.csv'\n",
        "\n",
        "# Remove previous file if it exists\n",
        "if os.path.exists(file_path):\n",
        "    os.remove(file_path)\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(name='outputs/dataset', exist_ok=True)\n",
        "\n",
        "# Save cleaned DataFrame to the file path\n",
        "df.to_csv(file_path, index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
